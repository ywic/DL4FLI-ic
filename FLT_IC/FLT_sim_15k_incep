from __future__ import print_function
import random
from keras.regularizers import l2
#import matplotlib.pyplot as plt
import scipy.ndimage
import numpy as np, h5py
import os, time, sys
import tensorflow as tf
import keras
from keras.regularizers import l2
from keras.models import Model
from keras.layers import BatchNormalization, Convolution2D, Input, SpatialDropout2D, UpSampling2D, MaxPooling2D, concatenate
from tensorflow.keras.layers import Activation, Layer
from keras.layers import Dense, Dropout, Conv1D, Input, Conv2D, add, Conv3D, Reshape
from keras.callbacks import History, EarlyStopping, ModelCheckpoint, CSVLogger
from itertools import cycle
#from sklearn import metrics
from tensorflow.keras.optimizers import RMSprop
from keras.utils import np_utils
from tensorflow.python.keras.backend import get_session
from tensorflow.keras.layers import PReLU
from tensorflow.keras.layers import Dropout
from keras.layers.convolutional import Convolution2D, MaxPooling2D, SeparableConv2D,Conv2DTranspose
from tensorflow.keras import backend as K
import tensorflow as tf
from tensorflow.keras.optimizers import Adagrad
from tensorflow.keras.optimizers import Nadam


class MemoryPrintingCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
      gpu_dict = tf.config.experimental.get_memory_info("GPU:0")
      
      tf.print('\n GPU memory details [current: {} gb, peak: {} gb]'.format(
          float(gpu_dict['current']) / (1024 ** 3), 
          float(gpu_dict['peak']) / (1024 ** 3)))
# Relevant resblock functions (Keras API)
def resblock_2D(num_filters, size_filter, x):
    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(x)
    Fx = Activation('relu')(Fx)
    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(Fx)
    output = add([Fx, x])
    output = Activation('relu')(output)
    return output

def resblock_2D_BN(num_filters, size_filter, x):
    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(x)
    Fx = BatchNormalization()(Fx)
    Fx = Activation('relu')(Fx)
    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(Fx)
    Fx = BatchNormalization()(Fx)
    output = add([Fx, x])
    #output = BatchNormalization()(output)
    output = Activation('relu')(output)
    return output

def resblock_3D_BN(num_filters, size_filter, x):
    Fx = Conv3D(num_filters, size_filter, padding='same', activation=None)(x)
    Fx = BatchNormalization()(Fx)
    Fx = Activation('relu')(Fx)
    Fx = Conv3D(num_filters, size_filter, padding='same', activation=None)(Fx)
    Fx = BatchNormalization()(Fx)
    output = add([Fx, x])
    #output = BatchNormalization()(output)
    output = Activation('relu')(output)
    return output

def xCeptionblock_2D_BN(num_filters, size_filter, x):
    Fx = SeparableConv2D(num_filters, size_filter, padding='same', activation=None)(x)
    Fx = BatchNormalization()(Fx)
    Fx = Activation('relu')(Fx)
    Fx = SeparableConv2D(num_filters, size_filter, padding='same', activation=None)(Fx)
    Fx = BatchNormalization()(Fx)
    output = add([Fx, x])
    output = Activation('relu')(output)
    return output



# # # # # # # # 3D-Model # # # # # # # #
def get_compiled_model():
    modelD = None
    xX = 28;
    yY = 28;
    t_data = Input(shape=(xX, yY, 160,1))
    tpsf = t_data
    tpsf = Conv3D(50,kernel_size=(1,1,10),strides=(1,1,5), padding='same', activation=None, data_format="channels_last")(tpsf)
    tpsf = BatchNormalization()(tpsf)
    tpsf = Activation('relu')(tpsf)
    tpsf = resblock_3D_BN(50, (1,1,5), tpsf)
    tpsf = Reshape((xX,yY,1600))(tpsf)
    tpsf = Conv2D(256, 1, padding='same', activation=None, data_format="channels_last")(tpsf)
    tpsf = BatchNormalization()(tpsf)
    tpsf = Activation('relu')(tpsf)
    tpsf = Conv2D(256, 1, padding='same', activation=None, data_format="channels_last")(tpsf)
    tpsf = BatchNormalization()(tpsf)
    tpsf = Activation('relu')(tpsf)

    tpsf = xCeptionblock_2D_BN(256, 1, tpsf)
    tpsf = xCeptionblock_2D_BN(256, 1, tpsf)

    # Short-lifetime branch
    imgT1 = Conv2D(64, 1, padding='same', activation=None)(tpsf)
    imgT1 = BatchNormalization()(imgT1)
    imgT1 = Activation('relu')(imgT1)
    imgT1 = Conv2D(32, 1, padding='same', activation=None)(imgT1)
    imgT1 = BatchNormalization()(imgT1)
    imgT1 = Activation('relu')(imgT1)
    imgT1 = Conv2D(1, 1, padding='same', activation=None)(imgT1)
    imgT1 = Activation('relu')(imgT1)


    # Long-lifetime branch
    imgT2 = Conv2D(64, 1, padding='same', activation=None)(tpsf)
    imgT2 = BatchNormalization()(imgT2)
    imgT2 = Activation('relu')(imgT2)
    imgT2 = Conv2D(32, 1, padding='same', activation=None)(imgT2)
    imgT2 = BatchNormalization()(imgT2)
    imgT2 = Activation('relu')(imgT2)
    imgT2 = Conv2D(1, 1, padding='same', activation=None)(imgT2)
    imgT2 = Activation('relu')(imgT2)


    # Long-lifetime branch
    imgT3 = Conv2D(64, 1, padding='same', activation=None)(tpsf)
    imgT3 = BatchNormalization()(imgT3)
    imgT3 = Activation('relu')(imgT3)
    imgT3 = Conv2D(32, 1, padding='same', activation=None)(imgT3)
    imgT3 = BatchNormalization()(imgT3)
    imgT3 = Activation('relu')(imgT3)
    imgT3 = Conv2D(1, 1, padding='same', activation=None)(imgT3)
    imgT3 = Activation('relu')(imgT3)


    # Amplitude-Ratio branch
    imga1 = Conv2D(64, 1, padding='same', activation=None)(tpsf)
    imga1 = BatchNormalization()(imga1)
    imga1 = Activation('relu')(imga1)
    imga1 = Conv2D(32, 1, padding='same', activation=None)(imga1)
    imga1 = BatchNormalization()(imga1)
    imga1 = Activation('relu')(imga1)
    imga1 = Conv2D(1, 1, padding='same', activation=None)(imga1)
    imga1 = Activation('relu')(imga1)
  


    # Amplitude-Ratio branch
    imga2 = Conv2D(64, 1, padding='same', activation=None)(tpsf)
    imga2 = BatchNormalization()(imga2)
    imga2 = Activation('relu')(imga2)
    imga2 = Conv2D(32, 1, padding='same', activation=None)(imga2)
    imga2 = BatchNormalization()(imga2)
    imga2 = Activation('relu')(imga2)
    imga2 = Conv2D(1, 1, padding='same', activation=None)(imga2)
    imga2 = Activation('relu')(imga2)


    modelD = Model(inputs=[t_data], outputs=[imgT1,imgT2, imgT3,imga1,imga2])
    rmsprop = RMSprop(lr=1e-6)

    modelD.compile(loss='mse',
              optimizer=rmsprop,
              metrics=['mae'])
    return modelD

import os
import numpy as np
import h5py
import tensorflow as tf
import sys
def load_custom_datasets(f_data, batch_size=32, validation_split=0.2):
    stacks = os.listdir(f_data)
    numS = int(len(stacks))

    nTG = 160  # Number of time-points
    xX = 28
    yY = 28

    tpsfD = np.ndarray(
        (numS, int(nTG), int(xX), int(yY), int(1)), dtype=np.float32
    )
    t1 = np.ndarray(
        (numS, int(xX), int(yY), int(1)), dtype=np.float32
    )
    t2 = np.ndarray(
        (numS, int(xX), int(yY), int(1)), dtype=np.float32
    )
    t3 = np.ndarray(
        (numS, int(xX), int(yY), int(1)), dtype=np.float32
    )
    a1 = np.ndarray(
        (numS, int(xX), int(yY), int(1)), dtype=np.float32
    )
    a2 = np.ndarray(
        (numS, int(xX), int(yY), int(1)), dtype=np.float32
    )
    i=0
    for d in stacks:
        try:
            with h5py.File(os.path.join(f_data, d), "r") as f:
                tpsfD[i, :, :, :, 0] = f.get('sigD')
                t1[i, :, :, 0] = f.get('t1')
                t2[i, :, :, 0] = f.get('t2')
                t3[i, :, :, 0] = f.get('t3')
                a1[i, :, :, 0] = f.get('a1')
                a2[i, :, :, 0] = f.get('a2')

            # If processing is successful, you can continue with the next file
            #print(f"Processed {d} successfully.")
            i += 1  # Increment the index  
      
        except OSError as e:
            # Handle the exception (corrupted file) here
            print(f"Error processing {d}: {e}")
            # Optionally, you can log the error or take other actions

        except Exception as e:
            # Handle other exceptions here, if needed
            print(f"An error occurred while processing {d}: {e}") 

    tpsfD = np.moveaxis(tpsfD, 1, -2)
    print(tpsfD.shape)
    # Split the data into training and validation sets
    num_val_samples = int(validation_split * numS)
    
    x_train_data = tpsfD[:-num_val_samples]
    x_val_data = tpsfD[-num_val_samples:]
    
    y_train = (t1[:-num_val_samples], t2[:-num_val_samples], t3[:-num_val_samples], a1[:-num_val_samples], a2[:-num_val_samples])
    y_val = (t1[-num_val_samples:], t2[-num_val_samples:], t3[-num_val_samples:], a1[-num_val_samples:], a2[-num_val_samples:])
    
    return (
        tf.data.Dataset.from_tensor_slices((x_train_data,y_train)).batch(batch_size),
        tf.data.Dataset.from_tensor_slices((x_val_data,y_val)).batch(batch_size),
        #tf.data.Dataset.from_tensor_slices(y_train).batch(batch_size),
        #tf.data.Dataset.from_tensor_slices(y_val).batch(batch_size),
       
    )
#tf.debugging.set_log_device_placement(True)
gpus = tf.config.list_logical_devices('GPU')

strategy = tf.distribute.MirroredStrategy(gpus)
print("Number of devices: {}".format(strategy.num_replicas_in_sync))
# Open a strategy scope.
with strategy.scope():
    f_data = '/rds/general/user/yw13515/home/FLT_data/NV1_noise_unia3'
    train_dataset, val_dataset = load_custom_datasets(f_data, batch_size=32, validation_split=0.2)# Create a MirroredStrategy.

    # Everything that creates variables should be under the strategy scope.
    # In general this is only model construction & `compile()`.
    model = get_compiled_model()

    fN = 'FLT6000unia3_Xcep' # Assign some name for weights and training/validation loss curves here
    # Setting patience (patience = 15 recommended)
    earlyStopping = EarlyStopping(monitor='val_loss', 
                              patience = 15,#15, 
                              verbose = 0,
                              mode = 'auto')
    # Save loss curve (mse) and MAE information over all trained epochs. (monitor = '' can be changed to focus on other tau parameters)
    modelCheckPoint = ModelCheckpoint(filepath=fN+'.h5', 
                                  monitor='val_loss', 
                                  save_best_only=True, 
                                  verbose=0)
    csv_logger = CSVLogger(fN+'.log')
    # Train the model on all available devices.
    model.fit(train_dataset, epochs=5000, validation_data=val_dataset, callbacks=[earlyStopping,csv_logger,modelCheckPoint,MemoryPrintingCallback()])


    # Test the model on all available devices.
    #model.evaluate(train_dataset,val_dataset)
